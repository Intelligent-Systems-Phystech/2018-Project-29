\documentclass[12pt,twoside]{article}
\usepackage{jmlda}
%\usepackage{notations}
\begin{document}
\Russian
%\NOREVIEWERNOTES
\title
    [Cross-Language Document Extractive Summarization with Neural Sequence Model] % TODO: название
    {Cross-Language Document Extractive Summarization with Neural Sequence Model}
\author
    [Захаров~П.\,С., Сельницкий~И.\,С., Кваша~П.\,А., Дьячков~Е.\,А, Петров~Е.\,Д.] % список авторов для колонтитула; не нужен, если основной список влезает в колонтитул
    {Захаров~П.\,С., Сельницкий~И.\,С., Кваша~П.\,А., Дьячков~Е.\,А, Петров~Е.\,Д.} % основной список авторов, выводимый в оглавление
    %[Захаров П.С, Сельницкий И.С., Кваша П.А., Дьячков Е.А, Петров Е.Д.] % список авторов, выводимый в заголовок; не нужен, если он не отличается от основного
\thanks
    {Научный руководитель:  Стрижов~В.\,В.
   Задачу поставил:  Хританков~А.\,С.
    Консультант:  Романов~А.\,В.}
\organization
    {Московский физико-технический институт}
\abstract
    { В данной работе представлена модель реферирования текстов на языке, отличном от текста документа. Для этого используется сокращение текста выбором предложений с последующим машинным переводом; при отборе предложений учитывается не только их содержание, но и оценка качества перевода. Исследуется зависимость качества сокращения от качества перевода. Перевод и сокращение осуществляются специально спроектированными для этих целей нейронными сетями. При этом базовая модель исследовалась на малом числе наборов данных; в этой работе идет дальнейшее рассмотрение переносимости этой модели на другие данные и внесение коррективов для улучшения модели в будущем.
\bigskip

\textbf{Ключевые слова}: \emph {Аннотирование текстов, машинный перевод, нейронные сети}.}

\maketitle

\section{Введение}

Данное исследование посвящено задаче реферирования, т.е. краткого изложения текстов. Задача машинного реферирования возникла в связи с развитием крупных хранилищ документов (в данном исследовании - статей), которые требуется представить в удобном для быстрой оценки виде. При решении задач подобного рода можно выделить два подхода: обобщение и извлечение. В первом случае сокращенный текст генерируется синтетически, в то время как второй подход отбирает предложения из исходного текста. В данной работе рассматривается в основном извлечение, т.к. оно проще в реализации и на настоящий момент показывает лучшие результаты \cite{journals/corr/NallapatiZZ16}. 

Необходимость делать сокращения текстов на других языках и развитие технологий машинного перевода подтолкнуло создание моделей, реализующих межъязыковое реферирование текстов (англ. Cross-Language Automatic Text Summarization). Наиболее простым решением проблемы является последовательное применение двух инструментов - моноязыкового реферирования и машинного перевода. Такие модели бывают двух типов - LateTrans и EarlyTrans - в первом случае сначала идет сокращение на языке оригинала, а затем перевод, во втором - наоборот. Обе концепции показали себя не лучшим образом в связи с несовершенством обеих технологий: неидеальный выход первой модели еще сильнее искажался второй. Wan и др.\cite{Wan:2010:CDS:1858681.1858775} предложили идею усовершенстованной LateTrans модели: при реферировании на языке оригинала учитывались не только информативность предложения, но и предсказание качества перевода. Помимо этого, Wan и др. \cite{Wan2018} реализовал систему, создающую изложения-кандидаты, полученные, разными способами, и отбирающую лучшие из них. Pontes и др.\cite{Pontes2018} использовали кластеризацию и сжатие исходных предложений для получения более информативных предложений для отбора.

Помимо совершенствования систем в целом, ведутся дальнейшие исследования в моноязыковом реферировании, \cite{journals/corr/NallapatiZZ16}\cite{DBLP:journals/corr/WuSCLNMKCGMKSJL16}. Можно также отметить работы по векторизации предложений \cite{conf/globalsip/ZhangSNPLSP17}. Модульная архитектура позволяет использовать эти наработки в содании более эффективных CLATS-моделей.

В данной работе предлагается использовать идею, аналогичную описанной у Wan \cite{Wan:2010:CDS:1858681.1858775} в приложении к сокращению с переводом с английского языка на русский. Данная архитектура предполагает учет оценки качества машинного перевода при отборе кандидатов из предложений. После совершенного с помощью SummaRunner2016 \cite{journals/corr/NallapatiZZ16} извлечения предложений на английском языке полученные сокращенные тексты переводятся. В базовой модели для перевода используется библиотека openNMT, основанная на \cite{journals/corr/BahdanauCB14}. При оценки качества обучения используется среднее значение кроссэнтропий для двух обучаемых нейронных сетей, для конечной оценки качества - ROUGE. Ставится задача решить проблемы модели сокращения текста, связанные с переносом на другую выборку документов, а также определить необходимость дополнительной предобработки текстов и границы применимости модели.

Для обучения SummaRunner используется исходная выборка - CNN/DailyMail corpus, а для обучения openNMT - параллельный корпус OPUS. Кроме того, имеются данные на русском языке для оценки качества итогового изложения. \textcolor{red}{(будет уточнено позднее, когда появится более подробная информация)}

\section{Постановка задачи}

В основе реализуемой модели лежит объединение модели моноязыкового аннотирования и модели машинного перевода. В следующих 2 подразделах по отдельности поставлены задачи для каждой из двух моделей, в третьем описано их объединение. \textcolor{red}{Нужно что-то сказать про гипотезу порождения данных. При созвоне что-то говорилось про i.i.d, но ведь это не так! мы для того и используем  RNN, чтобы использовать зависимости между словами, между предложениями. Или я что-то не понимаю?}

\subsection{\small{Извлечение}}

Для реферирования используется трехслойная двухсторонняя рекуррентная нейронная сеть. Пусть $\mathfrak{D} = \left(\mathfrak{V}, \mathbf{Y}\right)$ - выборка (предложения в документе и бинарный целевой вектор), где $\mathfrak{V} = \left\lbrace\mathbf{V}_i\right\rbrace, \mathbf{V}_i \in \mathbb{R}^{N_i\times n}$ - набор предложений, $i \in \left\lbrace 1,. M\right\rbrace$. При этом $\mathbf{V}_i = \left[\mathbf{v}_{ij}\right] \in \mathbb{R}^{N_i\times n}$ - предложения, состоящие из векторных представлений слов длиной $n$. Слои первых двух слоев нейронной сети состоят из нейронов, которые описываются двумя \textcolor{red}{гейтами - как правильно?} $\mathbf{u}_j$ и $\mathbf{r}_j$ по следующим формулам:
\begin{eqnarray}
\label{gates}
\mathbf{u_j} & = & \sigma\left( \mathbf{W}_{ux}\mathbf{x}_j+\mathbf{W}_{uh}\mathbf{h}_{j-1}+\mathbf{b}_j\right) \nonumber \\
\mathbf{r}_j & = & \sigma\left( \mathbf{W}_{rx}\mathbf{x}_j+\mathbf{W}_{rh}\mathbf{h}_{j-1}+\mathbf{b}_r\right) \\
\mathbf{h}'_j & = & tanh\left( \mathbf{W}_{hx}\mathbf{x}_j+\mathbf{W}_{hh}\left( \mathbf{r}_j\odot \mathbf{h}_{j-1}\right) + \mathbf{b}_j\right) \nonumber \\
\mathbf{h}_j & = & \left(1-\mathbf{u}_j\right)\odot \mathbf{h}'_j+\mathbf{u}_j\odot \mathbf{h}_{j-1} \nonumber
\end{eqnarray} 

На первом слое строится две цепочки нейронов для каждого предложения в тексте. Для одной цепочки $\mathbf{x}_j=\mathbf{v}_{ij}, j\in \left\lbrace 1..N_i\right\rbrace$, для другой $\mathbf{x}_j=\mathbf{v}_{iN_i-j}, j\in \left\lbrace 1..N_i\right\rbrace$ - во второй цепочке слова подаются в обратном порядке. Эту цепочку будем называть обратной, а первую = прямой. Здесь $N_i$ - количетсво слов в i-ом предложении

На втором слое строятся такие же цепочки нейронов, для прямой: 
\begin{equation}
\label{forwardsent}
\mathbf{x}_j = \frac{1}{N_j}\sum\limits_{k=1}^{N_j}\left[\mathbf{h}_{k,j}^f, \mathbf{h}_{k,j}^b\right],
\end{equation} 
где $\mathbf{h}_j^f$ - скрытое состояние нейронов прямой цепочки для j-ого предложения, а $\mathbf{h}_j^b$ - обратной. Квадратные скобки означают конкатенацию векторов. Для обратной цепочки:
\begin{equation}
\label{backwardsent}
\mathbf{x}_j = \frac{1}{N_{M-j}}\sum\limits_{k=1}^{N_{M-j}}\left[\mathbf{h}_{k,M-j}^f, \mathbf{h}_{k,M-j}^b\right],
\end{equation} 
где $M$ - число предложений в документе
Представление документа $\mathbf{d}$ формируется следующим образом:
\begin{equation}
\label{docrepr}
\mathbf{d}=tanh\left(W_d\frac{1}{M}\sum\limits_{j=1}^{M}\left[\mathbf{h}_j^f, \mathbf{h}_j^b\right]+\mathbf{b}_j\right),
\end{equation}
где $\mathbf{h}_j^f$ и $\mathbf{h}_j^b$ - скрытые состояния прямой и обратной цепочек на втором слое.

Для классификации используется логистический слой:
\begin{equation}
\label{logreg}
P\left(y_j=1|\mathbf{h}_j, \mathbf{s}_j, \mathbf{d}\right)=\sigma\left(\mathbf{W}_c\mathbf{h}_j+\mathbf{h}^T_j\mathbf{W}_s\mathbf{d}-\mathbf{h}_j^T\mathbf{W}_rtanh\left(\mathbf{s}_j\right)+\mathbf{W}_{ap}\mathbf{p}_j^a+\mathbf{W}_{rp}\mathbf{p}_j^r+\mathbf{b}\right)
\end{equation}
Здесь $\mathbf{s}_j$ - динамическое представление аннотации на j-ом шаге, а $\mathbf{p}_j^a$ и $\mathbf{p}_j^r$ - абсолютные и относительные положения в документе. Члены, обозначенные $\mathbf{W}$ и $\mathbf{b}$ с индексами, являются праметрами модели. Представление аннотации определяется следующим образом:
\begin{equation}
\label{sumrepr}
\mathbf{s}_j=\sum\limits_{i=1}^{j-1}\mathbf{h}_iP\left(y_i=1|\mathbf{h}_j, \mathbf{s}_j, \mathbf{d}\right)
\end{equation}

Ставится задача минимизовать логистическую функцию правдоподобия:
\begin{equation}
\begin{gathered}
\label{loglikelihood}
l\left(\mathbf{W}, \mathbf{b}\right) = -\sum\limits_{k=1}^{D}\sum\limits_{j=1}^{M_k}\left(y_j^klogP\left(y_j^k=1|\mathbf{h}_j^k, \mathbf{s}_j^k, \mathbf{d}_k\right)+ \\ 
+ \left(1-y_j^k\right)log\left(1-P\left(y_j^k=1|\mathbf{h}_j^k, \mathbf{s}_j^k, \mathbf{d}_k\right)\right) \rightarrow min
\end{gathered}
\end{equation}
Полученное мягкое предсказание в дальнейшем используется для формирования конечного прогноза.
\subsection{\small{Машинный перевод}}

В основе модели машинного перевода также лежит двухсторонняя рекуррентная нейронная сеть, внутренняя структура описывается (\ref{gates}). В момент $i$ вероятность сгенерировать $i$-ое слово перевода описывается
\begin{equation}
p\left(y_i|y_1,\dots,y_{i-1}, \mathbf{x}\right) = g\left(y_{i-1}, s_i, c_i\right),
\end{equation}
где $\mathbf{s}_i$ - скрытое состояние второго слоя на момент $i$,
\begin{equation}
\mathbf{s}_i=f\left(\mathbf{s}_{i-1}, y_{i-1}, \mathbf{c}_i\right)
\end{equation}
Контекстный вектор $\mathbf{c}_i$ определяется 
\begin{equation}
\mathbf{c}_i=\sum\limits_{j=1}^{L_x}\alpha_{ij}\mathbf{h}_j,
\end{equation}
где $\mathbf{h}_j = \left[\mathbf{h}^f_j, \mathbf{h}^b_j\right]$ - скрытые состояния нейронов первого, двухстороннего, слоя. Подробности описаны в \cite{journals/corr/BahdanauCB14}, \cite{DBLP:journals/corr/KleinKDSR17}.

Реализация openNMT\footnote{https://github.com/OpenNMT/OpenNMT-py} при переводе выдает несколько гипотез перевода с оценками вероятностей их правильности. Лучшая гипотеза является переводом предложения, а соотвествующая вероятность - оценкой его качества. 
%Пусть $\mathfrak{D} = \left(\mathfrak{V}, \mathbf{Y}\right) \subset \mathbb{R}^{m\times M}\times\mathbb{R}^M$ - выборка (объекты и целевой вектор), $\mathfrak{V}=\left[\mathbf{V}_i\right] \in \mathbb{R}^m$ - объекты (предложения). Подчеркнем, что ввиду решения другой задачи в этом подразделе представление предложений отличается - здесь они сами являются объектами, в то время как в предыдущем объектами были слова предложений. 

%Для предсказания качества машинного перевода используется $\epsilon$-SVR метод. Требуется найти гладкую функцию $\mathbf{f}$ такую, что:
%\begin{equation}
%\label{esvr}
%\underset{\mathbf{w}, b, \mathbf{\xi}, \mathbf{\xi^*}}{min} \frac{1}{2}\mathbf{w}^T\mathbf{w}+C\sum\limits_{i=1}^n\xi_i+C\sum\limits_{i=1}^n\xi_i^*
%\end{equation}
%при условии, что
%\begin{eqnarray}
%\mathbf{w}^T\mathbf{f}(\mathbf{V}_i)+b-y_i & \leq & \epsilon+\xi_i \nonumber \\
%y_i - \mathbf{w}^T\mathbf{f}(\mathbf{V}_i) - b & \leq & \epsilon+\xi^*_i \\
%\epsilon, \xi_i, \xi_i^* \geq 0, i=1,..,M \nonumber
%\end{eqnarray}
%
%Метриками качества являются
%\begin{eqnarray}
%MSE & = &\frac{1}{M}\sum\limits_{i=1}^{M}\left(\hat{y_i}-y_i\right)^2\quad \nonumber \text{-- среднеквадратичная ошибка и}  \\
%\rho & = & \frac{\sum\limits_{i=1}^{M}\left(y_i-\overline{y}\right)\left(\hat{y_i}-\overline{\hat{y}}\right)}{Ms_ys_{\hat{y}}}\quad \nonumber \text{ -- коэффициент Пирсона,}
%\end{eqnarray} 
%где $\overline{\hat{y}},\overline{y}$ - средние предсказанных и данных значений соответственно, а $s_y,s_\hat{y}$ - их среднеквадратичные отклонения.
%
%После обучения выданные оценки качества нормализуются максимальным значением в документе: $\tilde{y_i} = \frac{\hat{y_i}}{\underset{i}{max}\hat{y_i}}$
\subsection{\small{Получение итогового результата}}

На выходе моделей для каждого предложения $\mathbf{V}_i$ получены результаты \mbox{$y_{MT,i}, y_{ES,i}\in\left[0,1\right]$}. Итоговое предсказание строится по правилу
\begin{equation}
\label{final_pred}
y_{final,i}=y_{MT,i}\left(1-\lambda\right)+y_{ES,i}\lambda,
\end{equation}
где $\lambda$ - эмпирически подбираемый параметр, отражающий важность информативности предложения по сравнению с предполагаемым качеством перевода. К примеру, при $\lambda=1$ качество перевода вообще не учитывается. После этого отбирается несколько предложений с наивысшими оценками. Их количество зависит от настроек используемой метрики ROUGE. \textcolor{red}{(Каких конкретно? скорее всего, будет выбрано несколько - допишется, когда конкретно определимся)} После этого отбираются переводы предложений с лучшими оценками.
\section{Вычислительный эксперимент}
\subsection{\small{SummaRuNNer}}
Для обучения SummaRuNNer использовался датасет CNN/DailyMail - 193983 объекта. Размерность скрытого состояния - 200, количество эпох - 20. Размер словаря - 153824

\begin{figure}[!htbp]
\centering
\includegraphics[width=0.8\textwidth]{epoch_losses.eps}
\caption{Функция потерь на валидации в зависимости от числа прошедших эпох}
\end{figure}

\newpage
Кроме того, нейронная сеть была обучена на 1/8, 1/16 и 1/32 обучающей выборки; были сравнены результаты теста по метрике ROUGE:

\begin{figure}[!htbp]
\centering
\includegraphics[width=\textwidth]{learning_curve.eps}
\caption{Метрика качества извлечения в зависимости от размера выборки}
\end{figure}

Видно, что в случае отсутствия необходимости иметь максимально высокое качество возможно несколько сократить размер выборки, существенно сократив время обучения (Реализация SummaRuNNer такова, что после очередной эпохи результат сохраняется только в случае, когда модель показывает лучший результат на валидации, чем достигнутый прежде. Во всех случаях этот результат фактически достигался на 2 эпохе. Время указано в пересчете на 5 эпох.)

\begin{figure}[!htbp]
\centering
\includegraphics[width=0.5\textwidth]{time.eps}
\caption{Время обучения модели на различных размерах выборки}
\end{figure}

\newpage
Ниже произведено сравнение используемой модели с разными опциями и некоторыми аналогичными моделями. 

\begin{table}[!htbp]
\label{SummaTable}
\caption{Обучение SummaRuNNer на различных объемах выборки}
\begin{tabular}{|c|c|c|c|}
\hline
Модель & ROUGE-1 Recall & ROUGE-2 Recall & ROUGE-L Recall \\
\hline
Использ. реализация & 0.26341 & 0.11792 & 0.14068 \\
\hline
Реализация в \cite{journals/corr/NallapatiZZ16} & 0.262 & 0.108 & 0.144 \\
\hline
CNN-RNN\footnote{2 последних реализации взяты из \url{https://github.com/hpzhao/SummaRuNNer}} & 0.258 & 0.113 & 0.138 \\
\hline
Hierarch. Attention & 0.26 & 0.114 & 0.138 \\
\hline
\end{tabular}
\end{table}

\subsection{\small{OpenNMT}}

Обучение OpenNMT происходило на корпусе OpenSubtitles2018\footnote{\url{http://opus.nlpl.eu/OpenSubtitles2018.php}} - 20728084 объектов. Размерность скрытого состояния LSTM - 500. Сделано 800000 итераций, размер пачки данных - 64.

\begin{figure}[!htbp]
\centering
  \subfloat[Кросс-энтропия]{\includegraphics[width=0.5\textwidth]{Cross-entropy.eps}}
  \subfloat[Точность]{\includegraphics[width=0.5\textwidth]{Accuracy.eps}}\\
 \caption{Обучение OpenNMT}
  \label{NMT-train}
\end{figure}

Видно, что на валидации точность и perplexity стабилизируются:

\begin{figure}[!htbp]
\centering
  \subfloat[Perplexity]{\includegraphics[width=0.5\textwidth]{Val_Perplexity.eps}}
  \subfloat[Точность]{\includegraphics[width=0.5\textwidth]{Val_Accuracy.eps}}\\
 \caption{Валидация OpenNMT}
  \label{NMT-valid}
\end{figure}


\bibliographystyle{ieeetr}
\bibliography{Zakharov2018Title}

\end{document}
